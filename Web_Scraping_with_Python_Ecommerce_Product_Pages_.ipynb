{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WiemBorchani/Web-Scraping-with-Python/blob/main/Web_Scraping_with_Python_Ecommerce_Product_Pages_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYaU-XX7yPOF"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from time import sleep\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 1 : extract all the product links \n",
        "baseurl =\"https://www.wiki.tn/\"\n",
        "headers ={ \n",
        "        'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36'\n",
        "        }\n",
        "pclinks =[]\n",
        "for i in range(1,9) :\n",
        "  r = requests.get(f'https://www.wiki.tn/c/pc-portable-120.html#/page-{i}')\n",
        "  soup =BeautifulSoup(r.content ,'lxml')\n",
        "  productslist = soup.find_all('div', class_='product-image-container image')\n",
        "\n",
        "  for item in productslist :\n",
        "    for links in item.find_all('a',href=True):\n",
        "      pclinks.append(links['href'])"
      ],
      "metadata": {
        "id": "Klxsh25X-_67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHQ9qxKTygoV",
        "outputId": "6c37d687-19e8-415f-f1bf-5dbcc6313492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                name       price availability\n",
            "0        Pc Portable lenovo IP3 N4020 4Go 128Go Gris  749,000 DT     En Stock\n",
            "1  Pc Portable lenovo IP3 15IGL05 N4020 4Go 1To Gris  829,000 DT     En Stock\n",
            "2      Pc Portable Lenovo IP 3 15IGL05 N4020 4Go 1To  869,000 DT     En Stock\n",
            "3   Pc Portable lenovo IP 3 15ADA05 AMD 4Go 1To Gris  949,000 DT     En Stock\n",
            "4   Pc Portable lenovo IP 3 15ADA05 AMD 4Go 1To Noir  949,000 DT     En Stock\n"
          ]
        }
      ],
      "source": [
        "# Part 2 : 1.extract the name , price and availability of each product // 2.save it into a csv file\n",
        "pclist = []\n",
        "for link in pclinks  :\n",
        "  r = requests.get(link, headers=headers)\n",
        "  soup =BeautifulSoup(r.content ,'lxml')\n",
        "  name =soup.find('h1', itemprop=\"name\").text.strip()\n",
        "  price= soup.find ('span',id=\"our_price_display\").text.strip()\n",
        "  availability = soup.find ('span',class_=\"availability_value\").text.strip()\n",
        "  pc ={\n",
        "      'name' : name ,\n",
        "      'price': price,\n",
        "      'availability' : availability\n",
        "  }\n",
        "  pclist.append(pc)\n",
        "  sleep(0.5)  \n",
        "\n",
        "df = pd.DataFrame(pclist)\n",
        "df.to_csv('Wiki_PC.csv')\n",
        "print(df.head())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Web Scraping with Python: Ecommerce Product Pages..ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}